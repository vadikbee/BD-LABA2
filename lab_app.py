import streamlit as st
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder
import matplotlib.pyplot as plt
import matplotlib
import base64
import io

# ----- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ —Ç–µ–º–∞ "–ù–æ—á–Ω–∞—è —Å–∞–∫—É—Ä–∞" ---
st.set_page_config(
    page_title="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω –Ω–∞ –∫–≤–∞—Ä—Ç–∏—Ä—ã",
    page_icon="üå∏",
    layout="wide",
    initial_sidebar_state="expanded"
)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64
def get_base64(bin_file):
    with open(bin_file, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ñ–æ–Ω–∞
def set_background(jpg_file):
    bin_str = get_base64(jpg_file)
    page_bg_img = f"""
    <style>
    .stApp {{
    background-image: url("data:image/jpg;base64,{bin_str}");
    background-size: cover;
    }}
    </style>
    """
    st.markdown(page_bg_img, unsafe_allow_html=True)


# –ü–æ–ø—Ä–æ–±—É–µ–º —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ñ–æ–Ω, –µ—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
try:
    set_background('sakura.jpg')
except FileNotFoundError:
    st.warning("–§–∞–π–ª 'sakura.jpg' –Ω–µ –Ω–∞–π–¥–µ–Ω. –§–æ–Ω –Ω–µ –±—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")

# –ö–∞—Å—Ç–æ–º–Ω—ã–π CSS –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–µ–º—ã
st.markdown("""
<style>
    /* –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç */
    .stApp { color: #FFFFFF; }
    /* –ó–∞–≥–æ–ª–æ–≤–∫–∏ */
    h1, h2, h3 { color: #FFC0CB; /* –†–æ–∑–æ–≤—ã–π —Ü–≤–µ—Ç —Å–∞–∫—É—Ä—ã */ }
    /* –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å */
    .css-1d391kg { background-color: rgba(0, 0, 0, 0.6); border-right: 2px solid #FFC0CB; }
    /* –í–∏–¥–∂–µ—Ç—ã –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ */
    .stSelectbox, .stNumberInput, .stButton, .stSlider { color: #FFFFFF; }
    /* –ö–Ω–æ–ø–∫–∏ */
    .stButton>button { background-color: #FF69B4; color: #FFFFFF; border-radius: 8px; border: 1px solid #FFC0CB; }
    .stButton>button:hover { background-color: #FFC0CB; color: #000000; border: 1px solid #FF69B4; }
    /* –ú–µ—Ç—Ä–∏–∫–∏ */
    .stMetric { background-color: rgba(40, 40, 40, 0.7); border-radius: 10px; padding: 10px; border: 1px solid #FF69B4;}
    /* –†–∞–º–∫–∞ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ */
    .stPlotlyChart, .stImage, .stPyPlot { border: 1px solid #FFC0CB; border-radius: 10px; }
</style>
""", unsafe_allow_html=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ Matplotlib
matplotlib.rc('axes', facecolor='black', edgecolor='pink', labelcolor='white', titlecolor='pink')
matplotlib.rc('xtick', color='white')
matplotlib.rc('ytick', color='white')
matplotlib.rc('figure', facecolor='black', edgecolor='pink')
matplotlib.rc('legend', facecolor='black', edgecolor='pink', labelcolor='white')


# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º) ---

@st.cache_data
def load_data(file_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV —Ñ–∞–π–ª–∞."""
    try:
        df = pd.read_csv(file_path)
        return df
    except FileNotFoundError:
        st.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return None

#  –£–ë–†–ê–ù –î–ï–ö–û–†–ê–¢–û–† @st.cache_data
def preprocess_data_new(_df, is_train=False):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–æ–≤ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
    df_processed = _df.copy()

    # –£–õ–£–ß–®–ï–ù–ò–ï 1: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Feature Engineering)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º .get() –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ —Å—Ç–æ–ª–±—Ü–∞–º, –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–∂–µ—Ç –Ω–µ –±—ã—Ç—å –≤ input_df
    floor = df_processed.get('Floor')
    num_floors = df_processed.get('Number of floors')
    living_area = df_processed.get('Living area')
    area = df_processed.get('Area')
    kitchen_area = df_processed.get('Kitchen area')

    if floor is not None and num_floors is not None:
        # –î–æ–±–∞–≤–ª—è–µ–º .replace(0, 1) —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        df_processed['floor_ratio'] = floor / num_floors.replace(0, 1)
        df_processed['is_first_floor'] = (floor == 1).astype(int)
        df_processed['is_last_floor'] = (floor == num_floors).astype(int)

    if living_area is not None and area is not None:
        df_processed['living_area_ratio'] = living_area / area.replace(0, 1)

    if kitchen_area is not None and area is not None:
        df_processed['kitchen_area_ratio'] = kitchen_area / area.replace(0, 1)

    # –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–Ω—É–∂–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
    if 'id' in df_processed.columns:
        df_processed = df_processed.drop('id', axis=1)

    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    cols_to_fill = ['Living area', 'Kitchen area', 'Floor', 'Number of floors', 'floor_ratio', 'living_area_ratio', 'kitchen_area_ratio']
    for col in cols_to_fill:
        if col in df_processed.columns:
            # –î–ª—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ —Å—á–∏—Ç–∞–µ–º –º–µ–¥–∏–∞–Ω—É, –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é
            if is_train:
                median_val = df_processed[col].median()
                if 'medians' not in st.session_state:
                    st.session_state['medians'] = {}
                st.session_state['medians'][col] = median_val
            else:
                median_val = st.session_state.get('medians', {}).get(col, df_processed[col].median())
            df_processed[col] = df_processed[col].fillna(median_val)

    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö –º–æ–¥–æ–π
    for col in ['Apartment type', 'Renovation', 'Region', 'Metro station']:
        if col in df_processed.columns and df_processed[col].isnull().any():
            # –î–ª—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ —Å—á–∏—Ç–∞–µ–º –º–æ–¥—É, –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é
            if is_train:
                mode_val = df_processed[col].mode()[0]
                if 'modes' not in st.session_state:
                    st.session_state['modes'] = {}
                st.session_state['modes'][col] = mode_val
            else:
                mode_val = st.session_state.get('modes', {}).get(col, df_processed[col].mode()[0])
            df_processed[col] = df_processed[col].fillna(mode_val)


    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–æ–≤
    if 'one_hot_encoder' in st.session_state and 'ordinal_encoder' in st.session_state:
        ohe = st.session_state['one_hot_encoder']
        ordinal_encoder = st.session_state['ordinal_encoder']

        categorical_cols = ['Apartment type', 'Renovation']
        high_cardinality_cols = ['Metro station', 'Region']

        # One-Hot Encoding
        ohe_features = ohe.transform(df_processed[categorical_cols])
        ohe_df = pd.DataFrame(ohe_features, columns=ohe.get_feature_names_out(categorical_cols), index=df_processed.index)

        # Ordinal Encoding
        ordinal_features = ordinal_encoder.transform(df_processed[high_cardinality_cols])
        df_processed[high_cardinality_cols] = ordinal_features

        df_processed = pd.concat([df_processed.drop(columns=categorical_cols), ohe_df], axis=1)

    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å –æ–±—É—á–µ–Ω–∏–µ–º
    if 'train_columns' in st.session_state:
        train_cols = st.session_state.get('train_columns', [])
        current_cols = df_processed.columns.tolist()

        # –£–¥–∞–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å –≤ —Å–ø–∏—Å–∫–µ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        if 'Price' in train_cols:
            train_cols.remove('Price')

        missing_cols = set(train_cols) - set(current_cols)
        for c in missing_cols:
            df_processed[c] = 0

        extra_cols = set(current_cols) - set(train_cols)
        df_processed = df_processed.drop(columns=list(extra_cols), errors='ignore')

        df_processed = df_processed[train_cols]


    return df_processed

#  –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π —Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
@st.cache_resource
def train_models(X_train, y_train):
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏."""
    models = {}

    with st.spinner('–û–±—É—á–µ–Ω–∏–µ Random Forest...'):
        rf = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1,
                                 max_depth=15, min_samples_leaf=5, max_features=0.7)
        rf.fit(X_train, y_train)
        models['Random Forest'] = rf

    with st.spinner('–û–±—É—á–µ–Ω–∏–µ XGBoost...'):
        xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=300,
                                   learning_rate=0.05, max_depth=7, subsample=0.8,
                                   colsample_bytree=0.8, random_state=42, n_jobs=-1)
        xgb_reg.fit(X_train, y_train)
        models['XGBoost'] = xgb_reg

    return models

# --- –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
st.title('üå∏ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∫–≤–∞—Ä—Ç–∏—Ä –≤ –ú–æ—Å–∫–≤–µ')
st.write('–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç–æ–¥–∏—á–∫–∏.')

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
df_train_raw = load_data('MSK_Price_train.csv')
df_valid_raw = load_data('MSK_Price_valid.csv')

if df_train_raw is not None and df_valid_raw is not None:
    st.sidebar.header("–ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
    app_mode = st.sidebar.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª:",
        ["–û–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö", "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ", "–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–Ω—ã"]
    )

    # --- –†–ê–ó–î–ï–õ 1: –û–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö ---
    if app_mode == "–û–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö":
        st.header("1. –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        st.write("–ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:")
        st.dataframe(df_train_raw.head(10))
        st.write(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö: {df_train_raw.shape[0]} —Å—Ç—Ä–æ–∫, {df_train_raw.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤.")

        st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        st.write(df_train_raw.describe())

        st.subheader("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ–ø—É—Å–∫–∞—Ö:")
        buffer = io.StringIO()
        df_train_raw.info(buf=buffer)
        s = buffer.getvalue()
        st.text(s)

    # --- –†–ê–ó–î–ï–õ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ ---
    elif app_mode == "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ":
        st.header("2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")

        #  –ó–∞–º–µ–Ω–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–∞ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫—É—é —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é
        st.subheader("2.1. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (—Ü–µ–Ω—ã)")
        st.write("–¶–µ–Ω—ã –Ω–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å –∏–º–µ—é—Ç —Å–∏–ª—å–Ω–æ —Å–º–µ—â–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å '–¥–ª–∏–Ω–Ω—ã–º —Ö–≤–æ—Å—Ç–æ–º' –æ—á–µ–Ω—å –¥–æ—Ä–æ–≥–∏—Ö –∫–≤–∞—Ä—Ç–∏—Ä. –ß—Ç–æ–±—ã –º–æ–¥–µ–ª—å –ª—É—á—à–µ —Å–ø—Ä–∞–≤–ª—è–ª–∞—Å—å —Å —ç—Ç–∏–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º, –º—ã –ø—Ä–∏–º–µ–Ω–∏–º –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫—É—é —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –∫ —Ü–µ–Ω–∞–º.")

        col1, col2 = st.columns(2)
        fig, ax = plt.subplots()
        df_train_raw['Price'].hist(bins=100, ax=ax)
        ax.set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω –¥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏")
        ax.set_xlabel("–¶–µ–Ω–∞")
        ax.set_ylabel("–ß–∞—Å—Ç–æ—Ç–∞")
        col1.pyplot(fig)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫—É—é —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é
        y_log_transformed = np.log1p(df_train_raw['Price'])

        fig, ax = plt.subplots()
        y_log_transformed.hist(bins=100, ax=ax)
        ax.set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω –ø–æ—Å–ª–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏—è")
        ax.set_xlabel("Log(1 + –¶–µ–Ω–∞)")
        ax.set_ylabel("–ß–∞—Å—Ç–æ—Ç–∞")
        col2.pyplot(fig)
        st.info("–ö–∞–∫ –≤–∏–¥–Ω–æ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ, –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞–ª–æ –±–æ–ª–µ–µ '–Ω–æ—Ä–º–∞–ª—å–Ω—ã–º', —á—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª—è–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Ä–∞–±–æ—Ç–∞—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ.")

        # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        df_train_processed = df_train_raw.copy()
        df_train_processed['Price'] = y_log_transformed
        
        #  –û–±—É—á–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–æ–≤
        st.subheader("2.2. –û–±—É—á–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–æ–≤ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞")

        categorical_cols = ['Apartment type', 'Renovation']
        high_cardinality_cols = ['Metro station', 'Region']

        # –î–ª—è –æ–±—É—á–µ–Ω–∏—è –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö, –≥–¥–µ –ø—Ä–æ–ø—É—Å–∫–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –º–æ–¥–æ–π
        df_train_for_encoding = df_train_raw.copy()
        for col in categorical_cols + high_cardinality_cols:
            if df_train_for_encoding[col].isnull().any():
                df_train_for_encoding[col] = df_train_for_encoding[col].fillna(df_train_for_encoding[col].mode()[0])

        ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
        ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1) # -1 –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π

        ohe.fit(df_train_for_encoding[categorical_cols])
        ordinal_encoder.fit(df_train_for_encoding[high_cardinality_cols])

        st.session_state['one_hot_encoder'] = ohe
        st.session_state['ordinal_encoder'] = ordinal_encoder

        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        X_train_features = preprocess_data_new(df_train_processed.drop('Price', axis=1), is_train=True)
        y_train_log_values = df_train_processed['Price'].values

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –±—É–¥—É—â–µ–π —Å–≤–µ—Ä–∫–∏
        st.session_state['train_columns'] = X_train_features.columns.tolist()

        st.write("–î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        st.dataframe(X_train_features.head())

        #  –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏. y_train –∏ y_test —Ç–µ–ø–µ—Ä—å —Å–æ–¥–µ—Ä–∂–∞—Ç –ª–æ–≥–∞—Ä–∏—Ñ–º —Ü–µ–Ω—ã
        X_train, X_test, y_train_log, y_test_log = train_test_split(
            X_train_features, y_train_log_values, test_size=0.2, random_state=42
        )

        st.subheader("2.3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –æ—Ü–µ–Ω–∫–∞")
        models = train_models(X_train, y_train_log)
        st.session_state['models'] = models
        st.session_state['data_prepared'] = True

        st.write("–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ (Mean Absolute Error):")
        col1, col2 = st.columns(2)

        maes = {}
        for name, model in models.items():
            # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –ª–æ–≥–∞—Ä–∏—Ñ–º —Ü–µ–Ω—ã
            y_pred_log = model.predict(X_test)
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –º–∞—Å—à—Ç–∞–±—É —Ü–µ–Ω
            y_pred_original = np.expm1(y_pred_log)
            y_test_original = np.expm1(y_test_log)
            # –°—á–∏—Ç–∞–µ–º –æ—à–∏–±–∫—É –≤ —Ä—É–±–ª—è—Ö
            mae = mean_absolute_error(y_test_original, y_pred_original)
            maes[name] = mae
            if name == 'Random Forest':
                col1.metric(label=name, value=f"{mae:,.0f} —Ä—É–±.")
            else:
                col2.metric(label=name, value=f"{mae:,.0f} —Ä—É–±.")

        best_model_name = min(maes, key=maes.get)
        best_model = models[best_model_name]
        st.session_state['best_model_name'] = best_model_name # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        st.success(f"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: **{best_model_name}**")

        st.subheader(f"2.4. –ê–Ω–∞–ª–∏–∑ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: {best_model_name}")
        
        #  –î–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—ã –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –º–∞—Å—à—Ç–∞–±–µ
        y_test_original = np.expm1(y_test_log)
        y_pred_original = np.expm1(best_model.predict(X_test))
        
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.scatter(y_test_original, y_pred_original, alpha=0.3)
        ax.plot([y_test_original.min(), y_test_original.max()], [y_test_original.min(), y_test_original.max()], '--r', linewidth=2)
        ax.set_xlabel('–ù–∞—Å—Ç–æ—è—â–∞—è —Ü–µ–Ω–∞')
        ax.set_ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞')
        ax.set_title('–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ü–µ–Ω')
        st.pyplot(fig)

        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –í–°–ï–ô –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ
        st.subheader("2.5. –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        st.info("–≠—Ç–æ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –æ–Ω–∞ –Ω–µ –≤–∏–¥–µ–ª–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è. –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–ª–∞—Å—å –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏—è.")

        if not df_valid_raw.empty:
            y_valid_original = df_valid_raw['Price']
            X_valid_raw = df_valid_raw.drop('Price', axis=1)
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –∫ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º
            X_valid_processed = preprocess_data_new(X_valid_raw, is_train=False)

            valid_pred_log = best_model.predict(X_valid_processed)
            valid_pred_original = np.expm1(valid_pred_log)
            
            valid_mae = mean_absolute_error(y_valid_original, valid_pred_original)
            st.metric(label=f"MAE –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ ({best_model_name})", value=f"{valid_mae:,.0f} —Ä—É–±.")

            # --- –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö ---
            st.subheader("–ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ")
            st.write("–•–æ—Ç—è –º–æ–¥–µ–ª—å —Ç–µ–ø–µ—Ä—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö, –æ—à–∏–±–∫–∏ –¥–ª—è –æ—á–µ–Ω—å –¥–æ—Ä–æ–≥–∏—Ö –∫–≤–∞—Ä—Ç–∏—Ä –≤—Å–µ –µ—â–µ –º–æ–≥—É—Ç –±—ã—Ç—å –≤—ã—Å–æ–∫–∏–º–∏. –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ 10 –∫–≤–∞—Ä—Ç–∏—Ä —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –æ—à–∏–±–∫–æ–π.")
            
            error_df = pd.DataFrame({
                '–†–µ–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞': y_valid_original,
                '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞': valid_pred_original,
                '–ê–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞': np.abs(y_valid_original - valid_pred_original)
            }).astype(int)

            st.dataframe(error_df.sort_values(by='–ê–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞', ascending=False).head(10))
        else:
            st.warning("–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç. –û—Ü–µ–Ω–∫–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞.")

    # --- –†–ê–ó–î–ï–õ 3: –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ ---
    elif app_mode == "–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–Ω—ã":
        st.header("3. –°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑")

        if 'models' not in st.session_state or not st.session_state.get('data_prepared'):
            st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –≤ —Ä–∞–∑–¥–µ–ª '–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ', —á—Ç–æ–±—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏.")
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–µ –∏–º—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            best_model_name = st.session_state.get('best_model_name', "Random Forest")
            st.write(f"–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–≤–∞—Ä—Ç–∏—Ä—ã, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ ({best_model_name}).")

            final_model = st.session_state['models'][best_model_name]
            st.sidebar.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–≤–∞—Ä—Ç–∏—Ä—ã:")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º .dropna() –∏ .unique() –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —á–∏—Å—Ç—ã—Ö —Å–ø–∏—Å–∫–æ–≤ –¥–ª—è —Å–µ–ª–µ–∫—Ç–±–æ–∫—Å–æ–≤
            apartment_types = sorted(df_train_raw['Apartment type'].dropna().unique())
            renovations = sorted(df_train_raw['Renovation'].dropna().unique())
            regions = sorted(df_train_raw['Region'].dropna().unique())
            metro_stations = sorted(df_train_raw['Metro station'].dropna().unique())

            with st.sidebar.form(key='prediction_form'):
                num_rooms = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç", 1, 6, 2)
                area = st.slider("–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å, –º¬≤", 20.0, 200.0, 55.0)
                living_area = st.slider("–ñ–∏–ª–∞—è –ø–ª–æ—â–∞–¥—å, –º¬≤", 10.0, 150.0, 35.0)
                kitchen_area = st.slider("–ü–ª–æ—â–∞–¥—å –∫—É—Ö–Ω–∏, –º¬≤", 5.0, 50.0, 10.0)
                floor = st.slider("–≠—Ç–∞–∂", 1, 50, 5)
                num_floors = st.slider("–í—Å–µ–≥–æ —ç—Ç–∞–∂–µ–π –≤ –¥–æ–º–µ", 1, 50, 12)
                minutes_to_metro = st.slider("–ú–∏–Ω—É—Ç –¥–æ –º–µ—Ç—Ä–æ", 1, 60, 15)

                apartment_type = st.selectbox("–¢–∏–ø –∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤", apartment_types)
                renovation = st.selectbox("–†–µ–º–æ–Ω—Ç", renovations)
                region = st.selectbox("–†–∞–π–æ–Ω", regions)
                metro_station = st.selectbox("–°—Ç–∞–Ω—Ü–∏—è –º–µ—Ç—Ä–æ", metro_stations)

                submit_button = st.form_submit_button(label="–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å")

            if submit_button:
                input_data = {
                    'Minutes to metro': [minutes_to_metro], 'Number of rooms': [num_rooms],
                    'Area': [area], 'Living area': [living_area], 'Kitchen area': [kitchen_area],
                    'Floor': [floor], 'Number of floors': [num_floors],
                    'Metro station': [metro_station], 'Region': [region],
                    'Apartment type': [apartment_type], 'Renovation': [renovation]
                }
                input_df = pd.DataFrame(input_data)


                processed_input = preprocess_data_new(input_df, is_train=False)

                if processed_input is not None:
                    
                    prediction_log = final_model.predict(processed_input)[0]
                    prediction_original = np.expm1(prediction_log)
                    
                    st.success(f"## –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: **{prediction_original:,.0f} —Ä—É–±.**")
                else:
                    st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–≤–µ–¥–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –í–µ—Ä–Ω–∏—Ç–µ—Å—å –≤ —Ä–∞–∑–¥–µ–ª '–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ'.")